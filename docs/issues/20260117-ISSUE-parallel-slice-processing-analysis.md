# K2-18-ISSUE: Анализ возможности параллельной обработки слайсов в itext2kg_graph

**Дата:** 2026-01-17
**Статус:** Исследовано, отложено
**Компоненты:** itext2kg_graph, llm_client

## Контекст задачи

После анализа межслайсовых связей (см. `20260117-ISSUE-cross-slice-edges-analysis.md`) установлено, что контекстная цепочка LLM (`previous_response_id`) не влияет на построение графа. Возник вопрос: можно ли параллелить обработку слайсов для ускорения?

**Гипотеза:** Если LLM вызовы независимы, можно запускать их параллельно и потом мержить результаты.

## Анализ

### Что можно параллелить безопасно

**LLM вызовы** — полностью независимы:
- ConceptDictionary передаётся read-only
- Временные ID (`chunk_1`, `chunk_2`) локальны для слайса
- Финальные ID детерминированы: зависят только от `slice_token_start` + `node_offset`
- Нет зависимости от предыдущих ответов LLM

### Что нельзя параллелить без переписывания

**Merge патчей в граф** — shared mutable state:

```python
self.graph_nodes: List[Dict]     # все узлы
self.graph_edges: List[Dict]     # все рёбра  
self.node_ids: Dict[str, int]    # индексный словарь для дедупликации
```

### Выявленные race conditions

| Метод | Проблема |
|-------|----------|
| `_process_chunk_nodes()` | Два потока проверяют один `node_id`, оба не находят → оба добавляют → дубликат |
| `_process_chunk_nodes()` | Индекс `len(graph_nodes) + len(nodes_to_add) - 1` предполагает последовательное добавление — при параллельной обработке индексы "съезжают" |
| `_validate_edges()` | Ребро slice_5 ссылается на chunk из slice_3, если slice_3 ещё обрабатывается → `source_exists = False` → валидное ребро отклонено |
| `_deduplicate_patch_nodes()` | Snapshot `existing_ids` в момент вызова, другие потоки могут добавить узлы после snapshot → дубликаты проскакивают |
| `_add_mentions_edges()` | Читает текущее состояние графа, при параллельной обработке состояние неопределённо → пропущенные или дублирующиеся MENTIONS |

### Варианты архитектуры

**Вариант A: Двухфазная обработка**
```
Phase 1 (Parallel):  LLM calls → [patch_1, patch_2, ..., patch_N]
Phase 2 (Sequential): for patch in sorted_patches: merge(graph, patch)
```

Плюсы: race conditions исчезают, текущая логика merge работает as-is.
Минусы: хранение всех патчей в памяти или на диске.

**Вариант B: Lock-based merge**
```python
with self.graph_lock:
    self._add_to_graph(patch, slice_data)
```

Плюсы: merge может начаться сразу после получения патча.
Минусы: lock contention, `_add_mentions_edges()` сканирует весь граф → долго держит lock.

**Вариант C: Пост-обработка дубликатов**
```
Phase 1: Parallel merge (без дедупликации)
Phase 2: Single-pass dedup + MENTIONS generation
```

Плюсы: максимальная параллельность.
Минусы: переписывание логики дедупликации, MENTIONS генерация отдельным проходом.

### Ограничения TPM

Возможный bottleneck — лимит TPM:
- Слайс ~5k токенов
- Словарь ~10-30k токенов (растёт с контентом)
- Output ~2-5k токенов
- Итого: ~20-40k токенов на запрос

Максимальный TPM ограничен API, т.е. потребуется batch-обработка.

## Открытые вопросы (если вернёмся к задаче)

1. **Хранение патчей** — память vs диск? JSON? Pickle? Порядок merge?
2. **Батчинг** — как определять размер батча под конкретный TPM лимит?
3. **Failure handling** — что если патч 7 из 16 failed? Откат всего? Retry? Пропуск?
4. **Async vs threading** — `asyncio` для I/O-bound LLM вызовов? `ThreadPoolExecutor`?
5. **Прогресс-бар** — как показывать прогресс при асинхронной обработке?

## Выводы

### Факты

1. **LLM вызовы независимы** — параллелизация технически возможна
2. **Merge требует последовательности** — shared mutable state, множество race conditions
3. **TPM — возможный bottleneck** — параллелизация не увеличит throughput при текущих лимитах
4. **Complexity vs ROI** — существенный рефакторинг ради неочевидного выигрыша

### Решение

**Отложено.** Текущая последовательная архитектура:
- Простая и понятная
- Надёжная (один поток, нет race conditions)

Параллелизация добавляет значительную сложность без очевидного ROI в текущих условиях.

### Когда вернуться

- Появится use case с высоким TPM (1M+ tokens/min)
- Потребуется обработка очень большого корпуса с жёсткими временными рамками

## Связанные документы

- `20260117-ISSUE-cross-slice-edges-analysis.md` — анализ межслайсовых связей
- `docs/specs/itext2kg_graph.md` — спецификация модуля
- `docs/K2-18 LLM Reference.md` — референс по работе с LLM
