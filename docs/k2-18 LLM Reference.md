# K2‑18 · LLM Reference (single-point playbook)

> Цель документа — дать **единый, стабильный и краткий** референс по работе с LLM в проекте K2‑18, чтобы разработчики и автотесты опирались на общие правила. Примеры и большие выдержки из промптов намеренно опущены — они живут в исходниках.

---

## 1) Роль LLM в K2‑18 (почему промпты критичны)

K2‑18 реализует **iText2KG** — инкрементальный конвейер превращения учебных текстов в **ConceptDictionary** и **LearningChunkGraph**. LLM решает _строго разделённые_ задачи:
- извлечь и канонизировать понятия (термин, алиасы, определение);
- из фрагментов текста (**Slice**) сформировать **узлы** графа (Chunk / Concept / Assessment) и **рёбра** между ними с типами и весами;
- дополнить граф «дальними» связями, которые не попали в один контекст;
- поддерживать детерминированность: одинаковый вход ⇒ одинаковый выход (важно для автотестов и реплеев).

Качество промптов определяет **полноту** извлечения и **стабильность** результата: промпты фиксируют порядок решений, приоритеты типов рёбер, шкалы весов, соглашения по ID и т.д. Поэтому мы поддерживаем **один набор эталонных промптов** и обновляем их синхронно с кодом/тестами.

Учитывая статистическую природу работы LLM допустимы отклонения на выходных данных и это нормально.

---

## 2) Набор промптов и их назначение

* `itext2kg_concepts_extraction.md` - Инкрементально извлекает и **канонизирует** концепты по слайсам. Отдает обновлённый `ConceptDictionary` (только * новые/расширенные записи).
* `itext2kg_graph_extraction.md` - По одному Slice создаёт **узлы** (Chunk/Concept/Assessment) и **рёбра**. Отдает патч `chunk_graph_patch` для `* LearningChunkGraph_raw`.
* `refiner_longrange_fw.md` - **FORWARD**-проход: поиск недостающих дальних связей, где источник A **раньше** целей Bi. Список A→Bi с типами и весами * (усиляет/исправляет связи).
* `refiner_longrange_bw.md` - **BACKWARD**-проход: источник A **позже** целей Bi. Список A→Bi с типами и весами (углубляет/уточняет связи).

Общие свойства промптов: детерминизм, одинаковые шкалы весов, запрет слабых рёбер, строгая проверка форматов, опора на JSON‑схемы.

---

## 3) Политика словаря концептов (ConceptDictionary.schema.json)

**Сущность концепта** (обязательные поля):  
- `concept_id`: глобальный стабильный ID, паттерн `^[A-Za-z0-9:_-]+$`, формирование: `${slug}:p:${slugified_primary}`; при коллизии — суффиксы `-1`, `-2`…  
- `term.primary`: каноническое имя в исходном языке текста;  
- `term.aliases[]`: **уникальные (case‑insensitive)** синонимы/переводы; порядок не важен, но уникальность — критична;  
- `definition`: 1–2 предложения, самодостаточное объяснение; код/формулы/URL сохраняются **без изменений**.

**Правила извлечения** (суровый минимум):  
- Добавляем **только** если это новая сущность/значение; если совпадает по смыслу — расширяем `aliases`.  
- Не переопределяем уже существующие `definition` (улучшения — отдельным процессом качества).  
- Мультиязычность: `primary` — в языке источника, переводы в `aliases`.

**Валидация:** строго по `ConceptDictionary.schema.json`. Любое несоответствие — ошибка пайплайна.

---

## 4) Политика построения графа (LearningChunkGraph.schema.json)

### 4.1 Узлы
Типы узлов: `Chunk`, `Concept`, `Assessment`. Обязательные поля каждого узла:
- `id` (локальные временные ID для Chunk/Assessment: `chunk_1`, `assessment_1`…; для Concept — ровно `concept_id` из словаря);  
- `type`; `text`; `node_offset` (целое ≥ 0) — **позиция в Slice**;  
- `definition` (если применимо);  
- `difficulty` для `Chunk`/`Assessment` (1..5):  
  1 — короткое определение; 2 — простой пример/одна формула/микро‑код;  
  3 — описание алгоритма (3–5 концепций); 4 — доказательство/тяжёлый код; 5 — исследовательский/синтетический материал.

### 4.2 Допустимые типы рёбер
`PREREQUISITE`, `ELABORATES`, `EXAMPLE_OF`, `HINT_FORWARD`, `REFER_BACK`, `PARALLEL`, `TESTS`, `REVISION_OF`, `MENTIONS`.  
Каждое ребро: `source`, `target`, `type`, `weight∈[0,1]`, опц. `conditions` (семантическая причина **словами домена**, без ID).

### 4.3 Алгоритм приоритизации рёбер (внутри Slice)
Для **каждой неупорядоченной пары** {A,B} выполняем **две оценки** (A→B и B→A) по приоритету и берём **один лучший** результат:
1) `PREREQUISITE`; 2) `ELABORATES`; 3) `EXAMPLE_OF`; 4) `PARALLEL` (канон. направление: меньший `node_offset` → больший); 5) `TESTS`; 6) `REVISION_OF`; 7) `HINT_FORWARD`; 8) `REFER_BACK`.  
Далее — сравнение по весу; при равенстве — стабильный тай‑брейк (предпочесть **более поздний `node_offset` цели**). Запрещены циклы `PREREQUISITE`.

### 4.4 Веса и уточнение
Шкала дискретна (шаг 0.05):  
- ≥ 0.80 — сильная связь: дефолт для `PREREQUISITE`, `TESTS`, `REVISION_OF`;  
- 0.50–0.75 — ясная связь: дефолт для `ELABORATES`, `EXAMPLE_OF`, `PARALLEL`;  
- 0.30–0.45 — навигационные/слабые (`HINT_FORWARD`, `REFER_BACK`, `MENTIONS`);  
- \< 0.30 — **не создавать** ребро.  
Уточнение возможно позднее (Refiner повышает/заменяет тип/вес по правилам).

---

## 5) Направление связей и «дальние» связи

**Внутри Slice** направление задаётся алгоритмом из §4.3 — две оценки на пару.  
**Между Slice/частями книги** применяются два рефайнера:
- **Forward Pass**: A ― **раньше** кандидатов Bi (например, «введение» → «детализация» позднее). Приоритет: `PREREQUISITE` → (`TESTS`/`EXAMPLE_OF`/`PARALLEL`/`MENTIONS`) → `HINT_FORWARD`.  
- **Backward Pass**: A ― **позже** Bi (например, «доказательство» → «база»). Приоритет начинается с `ELABORATES`, затем (`REVISION_OF`/`TESTS`/`EXAMPLE_OF`/`PARALLEL`/`MENTIONS`) и, при отсутствии лучшего, `REFER_BACK`.

Оба прохода возвращают **только** релевантные A→Bi со строгой фильтрацией по весу (см. §4.4).

---

## 6) Роль эмбеддингов (коротко)

Эмбеддинги используются для **построения поискового пространства**, а не для принятия финального решения о типе связи:
- **Dedup**: кластеризация семантически близких узлов (FAISS, косинусное сходство) и слияние дубликатов с сохранением инцидентных рёбер.  
- **Refiner Longrange**: подбор top‑K кандидатов Bi для каждого A, затем LLM выбирает тип/вес.  
- (Опционально) **semantic chunking**/подсказки границ при нарезке; базовая нарезка — по семантическим границам текста (заголовки/абзацы/предложения).

Эмбеддинги **не** создают рёбра сами по себе; окончательное решение — за LLM согласно правилам §4–5.

---

## 7) Валидация, детерминизм и управление контекстом

- **JSON‑валидация**: все результаты должны соответствовать `ConceptDictionary.schema.json` и `LearningChunkGraph.schema.json`. Любое расхождение — ошибка шага.  
- **Детерминизм**: одинаковые входы → одинаковые выходы (строгий порядок обхода текста, стабильные правила суффиксов для ID, дискретизация весов).  
- **Контекст LLM**: используется `previous_response_id`, но глубина цепочки ограничивается конфигом; промпты не опираются на вероятностные ответы вне формализованных критериев.  
- **Repair‑reprompt**: на несоответствия схемам/правилам допускается автоматический исправляющий запрос.

---

## 8) I/O форматы (очень кратко)

- **Slice**: `{ id, order, source_file, slug, text, slice_token_start, slice_token_end }`  
- **ConceptDictionary**: `{ concepts: [ { concept_id, term:{primary, aliases[]}, definition } ... ], _meta }`  
- **LearningChunkGraph**: `{ nodes:[…], edges:[…], _meta }`  
  - `nodes` (см. §4.1), `edges` (см. §4.2); поля строго по схемам.
- Полные спецификации: `src/schemas/ConceptDictionary.schema.json`, `src/schemas/LearningChunkGraph.schema.json`.

---

## 9) Дополнения, о которых легко забыть

- **`node_offset` обязателен** для каждого узла (Chunk/Concept/Assessment).
- **`conditions`** у рёбер — короткая смысловая причина **без упоминания ID**.
- **Запрет циклов `PREREQUISITE`** и приоритет **детальных** узлов при `ELABORATES` (стрелка «глубже → база»).
- **Только один лучший тип ребра на пару узлов** (см. §4.3).
- **MENTIONS** создаётся только при явном упоминании концепта в тексте.
- **Вес < 0.30 — отбрасывать** (и в Graph, и в Refiner).

---

## Приложение A. Мини‑шаблоны структур

**A.1 ConceptDictionary (фрагмент)**
```json
{
  "concepts": [
    {
      "concept_id": "slug:p:primary-term",
      "term": { "primary": "Термин", "aliases": ["alias-1", "alias-2"] },
      "definition": "Краткое самодостаточное определение."
    }
  ]
}
```

**A.2 LearningChunkGraph (фрагмент)**
```json
{
  "nodes": [
    { "id": "chunk_1", "type": "Chunk", "text": "…", "node_offset": 0, "definition": "…", "difficulty": 2 },
    { "id": "slug:p:concept", "type": "Concept", "text": "Концепт", "node_offset": 120, "definition": "…" },
    { "id": "assessment_1", "type": "Assessment", "text": "…", "node_offset": 300, "difficulty": 3 }
  ],
  "edges": [
    { "source": "chunk_1", "target": "slug:p:concept", "type": "PREREQUISITE", "weight": 0.9, "conditions": "…" }
  ]
}
```

**A.3 Весовые уровни (сводная таблица)**
- 0.80–1.00 — сильные (`PREREQUISITE`, `TESTS`, `REVISION_OF`)  
- 0.50–0.75 — ясные (`ELABORATES`, `EXAMPLE_OF`, `PARALLEL`)  
- 0.30–0.45 — навигационные (`HINT_FORWARD`, `REFER_BACK`, `MENTIONS`)  
- < 0.30 — не создавать

---

## Приложение B. Где что лежит

- Промпты: `src/prompts/`  
- Схемы: `src/schemas/`  
